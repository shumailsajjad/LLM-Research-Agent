{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0781b3b6-9bbf-43b4-884a-c11701d5393b",
   "metadata": {},
   "source": [
    "# Master Project: Build a Research Agent with LangGraph, GPT-4o, RAG, Pinecone, ArXiv and Google SerpAPI "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9f08cd-2b2a-4c17-a75a-c72ecdd300b3",
   "metadata": {},
   "source": [
    "## 01 - Extracting Data from ArXiv into a Pandas DataFrame and Saving it as JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4046103-9014-4dc1-970b-95ebdab09c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -r requirements.txt -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1369622e-9c8a-4574-be95-d053ad2be0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# Namespace for ArXiv's Atom-based XML format.\n",
    "ARXIV_NAMESPACE = '{http://www.w3.org/2005/Atom}'\n",
    "\n",
    "def extract_from_arxiv(search_query='cat:cs.AI', max_results=100, json_file_path='files/arxiv_dataset.json'):\n",
    "    \"\"\"\n",
    "    Fetches papers from the ArXiv API based on a search query, saves them as JSON, \n",
    "    and returns a pandas DataFrame.\n",
    "\n",
    "    Args:\n",
    "        search_query (str): The search query for ArXiv (default is 'cat:cs.AI').\n",
    "        max_results (int): The maximum number of results to retrieve (default is 100).\n",
    "        json_file_path (str): File path where JSON data will be saved.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing the extracted paper information.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Construct the URL for the API request.\n",
    "    url = f'http://export.arxiv.org/api/query?search_query={search_query}&max_results={max_results}'\n",
    "    \n",
    "    # Send a GET request to the ArXiv API.\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    # Parse the XML response.\n",
    "    root = ET.fromstring(response.content)\n",
    "    \n",
    "    papers = []\n",
    "    \n",
    "    # Loop through each \"entry\" in the XML, representing a single paper.\n",
    "    for entry in root.findall(f'{ARXIV_NAMESPACE}entry'):\n",
    "        title = entry.find(f'{ARXIV_NAMESPACE}title').text.strip()\n",
    "        summary = entry.find(f'{ARXIV_NAMESPACE}summary').text.strip()\n",
    "\n",
    "        # Get the authors of the paper.\n",
    "        author_elements = entry.findall(f'{ARXIV_NAMESPACE}author')\n",
    "        authors = [author.find(f'{ARXIV_NAMESPACE}name').text for author in author_elements]\n",
    "\n",
    "        # Get the paper's URL.\n",
    "        paper_url = entry.find(f'{ARXIV_NAMESPACE}id').text\n",
    "        arxiv_id = paper_url.split('/')[-1]\n",
    "\n",
    "        # Check for the PDF link.\n",
    "        pdf_link = next((link.attrib['href'] for link in entry.findall(f'{ARXIV_NAMESPACE}link') \n",
    "                         if link.attrib.get('title') == 'pdf'), None)\n",
    "\n",
    "        papers.append({\n",
    "            'title': title,\n",
    "            'summary': summary,\n",
    "            'authors': authors,\n",
    "            'arxiv_id': arxiv_id,\n",
    "            'url': paper_url,\n",
    "            'pdf_link': pdf_link\n",
    "        })\n",
    "    \n",
    "    # Convert list into a pandas DataFrame.\n",
    "    df = pd.DataFrame(papers)\n",
    "    \n",
    "    # Save the DataFrame to a JSON file.\n",
    "    with open(json_file_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(papers, f, ensure_ascii=False, indent=4)\n",
    "        print(f'Data saved to {json_file_path} ...')\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d081fa-e45f-4e90-b62e-b27ad71f9626",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = extract_from_arxiv(max_results=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f4006e-99a7-4f3e-a3fd-6e80cce2ae66",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "file_name = 'files/arxiv_dataset.json'\n",
    "with  open(file_name, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362b4cf3-663b-431e-b5ab-23b98ea1a98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(data)\n",
    "df.sample(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c82a99-604e-4899-aefe-a74acd413121",
   "metadata": {},
   "source": [
    "## 02 - Downloading the Research Papers (PDFs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebbd8b0-a9e4-44e3-88be-4dcbf6273a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import os\n",
    "\n",
    "def download_pdfs(df, download_folder='files'):\n",
    "    \"\"\"\n",
    "    Downloads PDFs from URLs listed in the DataFrame and saves them to a specified folder. \n",
    "    The file names are stored in a new column 'pdf_file_name' in the DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing a 'pdf_link' column with URLs to download.\n",
    "        download_folder (str): Path to the folder where PDFs will be saved (default is 'files').\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: The original DataFrame with an additional 'pdf_file_name' column containing \n",
    "                      the paths of the downloaded PDF files or None if the download failed.\n",
    "    \"\"\"\n",
    "    \n",
    "    if not os.path.exists(download_folder):\n",
    "        os.makedirs(download_folder)\n",
    "    \n",
    "    pdf_file_names = []\n",
    "    \n",
    "    # Loop through each row to download PDFs\n",
    "    for index, row in df.iterrows():\n",
    "        pdf_link = row['pdf_link']\n",
    "        \n",
    "        try:\n",
    "            response = requests.get(pdf_link)\n",
    "            response.raise_for_status()\n",
    "    \n",
    "            file_name = os.path.join(download_folder, pdf_link.split('/')[-1]) + '.pdf'\n",
    "            pdf_file_names.append(file_name)\n",
    "    \n",
    "            # Save the downloaded PDF\n",
    "            with open(file_name, 'wb') as f:\n",
    "                f.write(response.content)\n",
    "            \n",
    "            print(f'PDF downloaded successfully and saved as {file_name}')\n",
    "        \n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f'Failed to download the PDF: {e}')\n",
    "            pdf_file_names.append(None)\n",
    "    \n",
    "    df['pdf_file_name'] = pdf_file_names\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2082ee0-8457-4844-9680-fd92e81dbd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = download_pdfs(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e864b5-8749-4174-9a60-b72d11ef021b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d6442f-9130-405e-8ad1-2302d81eb540",
   "metadata": {},
   "source": [
    "## 03 - Loading and Splitting PDF Files into Chunks, Expanding the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81050f98-2aa3-47b5-9e11-048335bef539",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "def load_and_chunk_pdf(pdf_file_name, chunk_size=512):\n",
    "    \"\"\"\n",
    "    Loads a PDF file and splits its content into chunks of a specified size.\n",
    "\n",
    "    Args:\n",
    "        file (str): Path to the PDF file to be loaded.\n",
    "        chunk_size (int): The maximum size of each chunk in characters (default is 512).\n",
    "\n",
    "    Returns:\n",
    "        List[Document]: A list of document chunks.\n",
    "    \"\"\"\n",
    "\n",
    "    print(f'Loading and splitting into chunks: {pdf_file_name}')\n",
    "\n",
    "    # Load the content of the PDF\n",
    "    loader = PyPDFLoader(pdf_file_name)\n",
    "    data = loader.load()\n",
    "\n",
    "    # Split the content into chunks with slight overlap to preserve context\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=64)\n",
    "    chunks = text_splitter.split_documents(data)\n",
    "\n",
    "    return chunks\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1607083-0b0c-45b3-848e-3cd6af2d19e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_df(df):\n",
    "    \"\"\"\n",
    "    Expands each row in the DataFrame by splitting PDF documents into chunks.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing 'pdf_file_name', 'arxiv_id', 'title', 'summary', \n",
    "                           'authors', and 'url' columns.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A new DataFrame where each row represents a chunk of the original document, \n",
    "                      with additional metadata such as chunk identifiers and relationships to \n",
    "                      adjacent chunks.\n",
    "    \"\"\"\n",
    "\n",
    "    expanded_rows = []  # List to store expanded rows with chunk information\n",
    "\n",
    "    # Loop through each row in the DataFrame\n",
    "    for idx, row in df.iterrows():\n",
    "        try:\n",
    "            chunks = load_and_chunk_pdf(row['pdf_file_name'])\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {row['pdf_file_name']}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # Loop over the chunks and construct a new DataFrame row for each\n",
    "        for i, chunk in enumerate(chunks):\n",
    "            prechunk_id = i-1 if i > 0 else ''  # Preceding chunk ID\n",
    "            postchunk_id = i+1 if i < len(chunks) - 1 else ''  # Following chunk ID\n",
    "\n",
    "            expanded_rows.append({\n",
    "                'id': f\"{row['arxiv_id']}#{i}\",  # Unique chunk identifier\n",
    "                'title': row['title'],\n",
    "                'summary': row['summary'],\n",
    "                'authors': row['authors'],\n",
    "                'arxiv_id': row['arxiv_id'],\n",
    "                'url': row['url'],\n",
    "                'chunk': chunk.page_content,  # Text content of the chunk\n",
    "                'prechunk_id': '' if i == 0 else f\"{row['arxiv_id']}#{prechunk_id}\",  # Previous chunk ID\n",
    "                'postchunk_id': '' if i == len(chunks) - 1 else f\"{row['arxiv_id']}#{postchunk_id}\"  # Next chunk ID\n",
    "            })\n",
    "\n",
    "    # Return a new expanded DataFrame\n",
    "    return pd.DataFrame(expanded_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800cbfe3-0823-422b-8aca-3f7b453659ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_df = expand_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7944105d-3182-487b-948d-3f5ec3a90bf6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "expanded_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d71e85f-0340-4f39-b27f-ac89a22f1489",
   "metadata": {},
   "source": [
    "## 04 - Building a Knowledge Base for the RAG System Using Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc79733-3b22-4f9c-b211-e35123d8a850",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "# Load the API keys from .env\n",
    "load_dotenv(find_dotenv(), override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2877f6da-15cf-43d2-8cd6-7c7edb098c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "from semantic_router.encoders import OpenAIEncoder\n",
    "\n",
    "# Check if 'OPENAI_API_KEY' is set; prompt if not\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY') or getpass('OpenAI API key: ')\n",
    "\n",
    "# Initialize the OpenAIEncoder with a specific model\n",
    "encoder = OpenAIEncoder(name='text-embedding-3-small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6036bb9-1601-47e4-b5c5-04e6b6b0a562",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "encoder('hello hallo hola salut')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e93d1e-7399-4e07-9a78-9a3aa440b9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dims = len(encoder('hello hallo hola salut')[0])\n",
    "dims"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d231bb-4d5d-4c05-8663-9d69e5bd5783",
   "metadata": {},
   "source": [
    "## 05 - Creating a Pinecone Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050b2392-fe04-4b55-9288-b0b08c98cc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "# Check if 'PINECONE_API_KEY' is set; prompt if not\n",
    "api_key = os.getenv('PINECONE_API_KEY') or getpass('Pinecone API key: ')\n",
    "\n",
    "# Initialize the Pinecone client\n",
    "pc = Pinecone(api_key=api_key)\n",
    "\n",
    "# Define the serverless specification for Pinecone (AWS region 'us-east-1')\n",
    "spec = ServerlessSpec(\n",
    "    cloud='aws', \n",
    "    region='us-east-1'\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269d128f-927b-43ca-b5d8-b8e17669e338",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Define the name of the index\n",
    "index_name = 'langgraph-research-agent'\n",
    "\n",
    "# Check if the index exists; create it if it doesn't\n",
    "if index_name not in pc.list_indexes().names():\n",
    "    pc.create_index(\n",
    "        index_name,\n",
    "        dimension=dims,  # Embedding dimension (1536)\n",
    "        metric='cosine',\n",
    "        spec=spec  # Cloud provider and region specification\n",
    "    )\n",
    "\n",
    "    # Wait until the index is fully initialized\n",
    "    while not pc.describe_index(index_name).status['ready']:\n",
    "        time.sleep(1)\n",
    "\n",
    "# Connect to the index\n",
    "index = pc.Index(index_name)\n",
    "\n",
    "# Add a short delay before checking the stats\n",
    "time.sleep(1)\n",
    "\n",
    "# View the index statistics\n",
    "index.describe_index_stats()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1919ce-f239-4731-8fe7-b6d0794814d4",
   "metadata": {},
   "source": [
    "## 06 - Populating the Knowledge Base and Uploading it to Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c36f4f7-7414-479e-958a-cd75cc768dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_df.iloc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7561ecf9-b142-4ca5-968f-02436403cfb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "data = expanded_df\n",
    "batch_size = 64  # Set batch size\n",
    "\n",
    "# Loop through the data in batches, using tqdm for a progress bar\n",
    "for i in tqdm(range(0, len(data), batch_size)):\n",
    "    i_end = min(len(data), i + batch_size)  # Define batch endpoint\n",
    "    batch = data[i:i_end].to_dict(orient='records')  # Slice data into a batch\n",
    "\n",
    "    # Extract metadata for each chunk in the batch\n",
    "    metadata = [{\n",
    "        'arxiv_id': r['arxiv_id'],\n",
    "        'title': r['title'],\n",
    "        'chunk': r['chunk'],\n",
    "    } for r in batch]\n",
    "    \n",
    "    # Generate unique IDs for each chunk\n",
    "    ids = [r['id'] for r in batch]\n",
    "    \n",
    "    # Extract the chunk content\n",
    "    chunks = [r['chunk'] for r in batch]\n",
    "    \n",
    "    # Convert chunks into embeddings\n",
    "    embeds = encoder(chunks)\n",
    "    \n",
    "    # Upload embeddings, IDs, and metadata to Pinecone\n",
    "    index.upsert(vectors=zip(ids, embeds, metadata))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f675265c-9e9e-4465-8c73-919c667330aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the index statistics.\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380bdc56-4429-469b-8c08-c778915fc371",
   "metadata": {},
   "source": [
    "## 07 - Implementing the ArXiv Fetch Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1055d13d-f882-4307-aa0b-18f364c47f35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "# Specify the arXiv ID for the paper\n",
    "arxiv_id = '1706.03762'\n",
    "\n",
    "# Make a GET request to retrieve the page for the specified paper\n",
    "res = requests.get(f'https://arxiv.org/abs/{arxiv_id}')\n",
    "\n",
    "# Access the content of the response as a string (HTML)\n",
    "res.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3b2261-8435-4e1a-9e4d-14047b4e3323",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Compile a regular expression pattern to find the abstract in the HTML response\n",
    "abstract_pattern = re.compile(\n",
    "    r'<blockquote class=\"abstract mathjax\">\\s*<span class=\"descriptor\">Abstract:</span>\\s*(.*?)\\s*</blockquote>',\n",
    "    re.DOTALL\n",
    ")\n",
    "\n",
    "# Search for the abstract in the HTML response text\n",
    "re_match = abstract_pattern.search(res.text)\n",
    "\n",
    "# Check if the abstract was found and print it; otherwise, display an error message\n",
    "if re_match:\n",
    "    print(re_match.group(1))\n",
    "else:\n",
    "    print('Abstract not found.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d506422f-4a3d-47d5-81a3-5a03c7aa7ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "import requests\n",
    "import re\n",
    "\n",
    "# Compile a regular expression pattern to find the abstract in the HTML response\n",
    "abstract_pattern = re.compile(\n",
    "    r'<blockquote class=\"abstract mathjax\">\\s*<span class=\"descriptor\">Abstract:</span>\\s*(.*?)\\s*</blockquote>',\n",
    "    re.DOTALL\n",
    ")\n",
    "\n",
    "@tool('fetch_arxiv')\n",
    "def fetch_arxiv(arxiv_id: str) -> str:\n",
    "    '''Fetches the abstract from an ArXiv paper given its ArXiv ID.\n",
    "\n",
    "    Args:\n",
    "        arxiv_id (str): The ArXiv paper ID.\n",
    "    \n",
    "    Returns:\n",
    "        str: The extracted abstract text from the ArXiv paper.\n",
    "    '''\n",
    "\n",
    "    res = requests.get(f'https://arxiv.org/abs/{arxiv_id}')\n",
    "    \n",
    "    re_match = abstract_pattern.search(res.text)\n",
    "\n",
    "    return re_match.group(1) if re_match else 'Abstract not found.'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7939006-a53e-41a8-88d4-9a036cb5bb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the ArXiv paper ID and invoking the tool with that ID.\n",
    "arxiv_id = '1706.03762'\n",
    "output = fetch_arxiv.invoke(input={'arxiv_id': arxiv_id})\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f923bc5c-2c2d-4ca9-ae80-24f6635a245d",
   "metadata": {},
   "source": [
    "## 08 - Implementing the Web Search Tools with Google SerpAPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519ab293-c41f-427c-ac9d-265307b18db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "# Load the API keys from .env\n",
    "load_dotenv(find_dotenv(), override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7968a061-30f4-495a-839b-d56f22770672",
   "metadata": {},
   "outputs": [],
   "source": [
    "from serpapi import GoogleSearch\n",
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "# Set up the SerpAPI request parameters, including the API key.\n",
    "serpapi_params = {\n",
    "    'engine': 'google',  \n",
    "    'api_key': os.getenv('SERPAPI_KEY') or getpass('SerpAPI key: ')  # Get the API key securely.\n",
    "}\n",
    "\n",
    "# Perform a Google search for the keyword \"water\" and limit the results to 5.\n",
    "search = GoogleSearch({\n",
    "    **serpapi_params,\n",
    "    'q': 'water',\n",
    "    'num': 5\n",
    "})\n",
    "\n",
    "\n",
    "# Extract the main search results from the API response.\n",
    "results = search.get_dict().get('organic_results', [])\n",
    "\n",
    "# Format the search results for readability.\n",
    "formatted_results = '\\n---\\n'.join(\n",
    "    ['\\n'.join([x['title'], x['snippet'], x['link']]) for x in results]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7303a50c-68f6-4293-8ea4-4b0a60782339",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(formatted_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247da198-6afd-4115-b34b-4936e8c69373",
   "metadata": {},
   "outputs": [],
   "source": [
    "from serpapi import GoogleSearch\n",
    "\n",
    "# Define the 'web_search' tool using the '@tool' decorator.\n",
    "@tool('web_search')\n",
    "def web_search(query: str) -> str:\n",
    "    '''Finds general knowledge information using a Google search.\n",
    "\n",
    "    Args:\n",
    "        query (str): The search query string.\n",
    "    \n",
    "    Returns:\n",
    "        str: A formatted string of the top search results, including title, snippet, and link.\n",
    "    '''\n",
    "\n",
    "    search = GoogleSearch({\n",
    "        **serpapi_params,  \n",
    "        'q': query,        \n",
    "        'num': 5         \n",
    "    })\n",
    "   \n",
    "    results = search.get_dict().get('organic_results', [])\n",
    "    formatted_results = '\\n---\\n'.join(\n",
    "        ['\\n'.join([x['title'], x['snippet'], x['link']]) for x in results]\n",
    "    )\n",
    "    \n",
    "    # Return the formatted results or a 'No results found.' message if no results exist.\n",
    "    return formatted_results if results else 'No results found.'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70901700-0e16-4958-9e99-c8f64dcfcc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invoke the 'web_search' tool with the query 'water on mars'\n",
    "output = web_search.invoke(input={'query': 'water on mars'})\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9456a3fe-884d-4bf4-9bba-d4f0dc0dd776",
   "metadata": {},
   "source": [
    "## 09 - Creating RAG Tools for Retrieval-Augmented Generation (RAG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83193680-a36a-4aa7-9a64-f649cffc665e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_rag_contexts(matches: list) -> str:\n",
    "    '''Formats the retrieved context matches into a readable string format.\n",
    "\n",
    "    Args:\n",
    "        matches (list): A list of matched documents with metadata.\n",
    "    \n",
    "    Returns:\n",
    "        str: A formatted string of document titles, chunks, and ArXiv IDs.\n",
    "    '''\n",
    "    formatted_results = []\n",
    "    \n",
    "    # Loop through each match and extract its metadata.\n",
    "    for x in matches:\n",
    "        text = (\n",
    "            f\"Title: {x['metadata']['title']}\\n\"\n",
    "            f\"Chunk: {x['metadata']['chunk']}\\n\"\n",
    "            f\"ArXiv ID: {x['metadata']['arxiv_id']}\\n\"\n",
    "        )\n",
    "        # Append each formatted string to the results list.\n",
    "        formatted_results.append(text)\n",
    "    \n",
    "    # Join all the individual formatted strings into one large string.\n",
    "    return '\\n---\\n'.join(formatted_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5938e85-3697-457b-a408-fac019ef8070",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def rag_search_filter(query: str, arxiv_id: str) -> str:\n",
    "    '''Finds information from the ArXiv database using a natural language query and a specific ArXiv ID.\n",
    "\n",
    "    Args:\n",
    "        query (str): The search query in natural language.\n",
    "        arxiv_id (str): The ArXiv ID of the specific paper to filter by.\n",
    "    \n",
    "    Returns:\n",
    "        str: A formatted string of relevant document contexts.\n",
    "    '''\n",
    "    \n",
    "    # Encode the query into a vector representation.\n",
    "    xq = encoder([query])\n",
    "    \n",
    "    # Perform a search on the Pinecone index, filtering by ArXiv ID.\n",
    "    xc = index.query(vector=xq, top_k=6, include_metadata=True, filter={'arxiv_id': arxiv_id})\n",
    "    \n",
    "    # Format and return the search results.\n",
    "    return format_rag_contexts(xc['matches'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e476c9-f570-44d8-98da-110439fbe79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool('rag_search')\n",
    "def rag_search(query: str) -> str:\n",
    "    '''Finds specialist information on AI using a natural language query.\n",
    "\n",
    "    Args:\n",
    "        query (str): The search query in natural language.\n",
    "    \n",
    "    Returns:\n",
    "        str: A formatted string of relevant document contexts.\n",
    "    '''\n",
    "    \n",
    "    # Encode the query into a vector representation.\n",
    "    xq = encoder([query])\n",
    "    \n",
    "    # Perform a broader search without filtering by ArXiv ID.\n",
    "    xc = index.query(vector=xq, top_k=5, include_metadata=True)\n",
    "    \n",
    "    # Format and return the search results.\n",
    "    return format_rag_contexts(xc['matches'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3dc5f8e-8a47-4db2-acda-90b464ec7cdf",
   "metadata": {},
   "source": [
    "## 10 - Implementing the Final Answer Generation Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefece23-e266-4ca1-9ceb-90c6aa20f361",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "# Define the 'final_answer' tool to compile the research report.\n",
    "@tool\n",
    "def final_answer(\n",
    "    introduction: str,\n",
    "    research_steps: str or list,\n",
    "    main_body: str,\n",
    "    conclusion: str,\n",
    "    sources: str or list\n",
    ") -> str:\n",
    "    '''Returns a natural language response in the form of a research report.\n",
    "\n",
    "    Args:\n",
    "        introduction (str): A short paragraph introducing the user's question and the topic.\n",
    "        research_steps (str or list): Bullet points or text explaining the steps taken for research.\n",
    "        main_body (str): The bulk of the answer, 3-4 paragraphs long, providing high-quality information.\n",
    "        conclusion (str): A short paragraph summarizing the findings.\n",
    "        sources (str or list): A list or text providing the sources referenced during the research.\n",
    "\n",
    "    Returns:\n",
    "        str: A formatted research report string.\n",
    "    '''\n",
    "\n",
    "    # Format research steps if given as a list.\n",
    "    if isinstance(research_steps, list):\n",
    "        research_steps = '\\n'.join([f'- {r}' for r in research_steps])\n",
    "    \n",
    "    # Format sources if given as a list.\n",
    "    if isinstance(sources, list):\n",
    "        sources = '\\n'.join([f'- {s}' for s in sources])\n",
    "    \n",
    "    # Construct and return the final research report.\n",
    "    return f'{introduction}\\n\\nResearch Steps:\\n{research_steps}\\n\\nMain Body:\\n{main_body}\\n\\n \\\n",
    "    Conclusion:\\n{conclusion}\\n\\nSources:\\n{sources}'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ced764-167d-4b5f-bdde-96e90c33a5f4",
   "metadata": {},
   "source": [
    "## 11 - Initializing the \"Oracle\" LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1941ac-aaf6-4a01-af18-6bcf604c93b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "# Define the system prompt guiding the AI's decision-making process.\n",
    "system_prompt = (\n",
    "    '''You are the oracle, the great AI decision-maker.\n",
    "    Given the user's query, you must decide what to do with it based on the\n",
    "    list of tools provided to you.\n",
    "\n",
    "    If you see that a tool has been used (in the scratchpad) with a particular\n",
    "    query, do NOT use that same tool with the same query again. Also, do NOT use\n",
    "    any tool more than twice (i.e., if the tool appears in the scratchpad twice, do\n",
    "    not use it again).\n",
    "\n",
    "    You should aim to collect information from a diverse range of sources before\n",
    "    providing the answer to the user. Once you have collected plenty of information\n",
    "    to answer the user's question (stored in the scratchpad), use the final_answer tool.'''\n",
    ")\n",
    "\n",
    "\n",
    "# Create a prompt template for the conversation flow.\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    ('system', system_prompt),  # Define the AI's role and rules.\n",
    "    \n",
    "    # Insert past chat messages to maintain context.\n",
    "    MessagesPlaceholder(variable_name='chat_history'),\n",
    "    \n",
    "    # Insert user's input dynamically.\n",
    "    ('user', '{input}'),\n",
    "    \n",
    "    # Include the assistant's scratchpad to track tool usage and intermediate steps.\n",
    "    ('assistant', 'scratchpad: {scratchpad}'),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf002d5-c1b1-4aed-965c-90160f265144",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import ToolCall, ToolMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "\n",
    "# Initialize the OpenAI language model with specific settings.\n",
    "llm = ChatOpenAI(\n",
    "    model='gpt-4o',\n",
    "    openai_api_key=os.environ['OPENAI_API_KEY'],\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "# Define the list of tools available to the oracle.\n",
    "tools = [\n",
    "    rag_search_filter,\n",
    "    rag_search,\n",
    "    fetch_arxiv,\n",
    "    web_search,\n",
    "    final_answer\n",
    "]\n",
    "\n",
    "# Function to create the scratchpad from the intermediate tool calls.\n",
    "def create_scratchpad(intermediate_steps: list[ToolCall]) -> str:\n",
    "    research_steps = []\n",
    "    \n",
    "    # Loop over each step and process tool calls with actual outputs.\n",
    "    for i, action in enumerate(intermediate_steps):\n",
    "        if action.log != 'TBD':\n",
    "            research_steps.append(\n",
    "                f'Tool: {action.tool}, input: {action.tool_input}\\n'\n",
    "                f'Output: {action.log}'\n",
    "            )\n",
    "    \n",
    "    # Join the research steps into a readable log.\n",
    "    return '\\n---\\n'.join(research_steps)\n",
    "\n",
    "# Define the oracle's decision-making pipeline.\n",
    "oracle = (\n",
    "    {\n",
    "        'input': lambda x: x['input'],\n",
    "        'chat_history': lambda x: x['chat_history'],\n",
    "        'scratchpad': lambda x: create_scratchpad(intermediate_steps=x['intermediate_steps']),\n",
    "    }\n",
    "    | prompt\n",
    "    | llm.bind_tools(tools, tool_choice='any')\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9687cca-2406-47bb-b69c-d8dcadb4a242",
   "metadata": {},
   "source": [
    "## 12 -  Testing the Oracle and the Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9b6e43-c767-40c1-a5c8-f9915eab5a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input = 'Tell me something interesting about dynamic backtracking AI and LLMs'\n",
    "# input = 'Who won the Super Bowl 2024?'\n",
    "input = 'What is the ArXiv paper with the ID 2407.21783 all about?'\n",
    "# Create the inputs dictionary, containing the user's query and initial empty chat history and intermediate steps.\n",
    "inputs = {\n",
    "    'input': input,\n",
    "    'chat_history': [],\n",
    "    'intermediate_steps': [],\n",
    "}\n",
    "\n",
    "# Invoke the oracle with the inputs, processing the query and returning a response.\n",
    "out = oracle.invoke(inputs)\n",
    "\n",
    "# Display the oracle's response.\n",
    "print(out)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c048e5-d647-417c-b433-2b6682265aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the name of the tool\n",
    "out.tool_calls[0]['name']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e54264a-4621-44bc-a8d3-097d39160a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the tool's arguments\n",
    "out.tool_calls[0]['args']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3198867c-1d30-44f7-9f0f-e5ea03b8f293",
   "metadata": {},
   "outputs": [],
   "source": [
    "##  Building a Decision-Making Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4aec02d-2559-461a-aa3f-c3e05cb4f8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_oracle(): main function that executes the oracle and processes its output to extract the relevant tool and its arguments.\n",
    "# We'll use this information to update the state for future steps.\n",
    "def run_oracle(state: dict) -> dict:\n",
    "    '''Runs the oracle and processes the output to extract tool information.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current state containing the 'intermediate_steps'.\n",
    "\n",
    "    Returns:\n",
    "        dict: A new state with updated 'intermediate_steps' including the tool action.\n",
    "    '''\n",
    "    \n",
    "    print('run_oracle')\n",
    "    print(f'intermediate_steps: {state[\"intermediate_steps\"]}')\n",
    "    \n",
    "    # Invoke the oracle with the current state.\n",
    "    out = oracle.invoke(state)\n",
    "\n",
    "    # Extract the tool name and its arguments from the oracle's response.\n",
    "    tool_name = out.tool_calls[0]['name']\n",
    "    tool_args = out.tool_calls[0]['args']\n",
    "\n",
    "    # Create an AgentAction object, which records the tool used and the input provided.\n",
    "    action_out = AgentAction(\n",
    "        tool=tool_name,\n",
    "        tool_input=tool_args,\n",
    "        log='TBD'  # To be determined later after the tool runs.\n",
    "    )\n",
    "\n",
    "    # Return a new state with updated 'intermediate_steps'.\n",
    "    return {\n",
    "        'intermediate_steps': [action_out]\n",
    "    }\n",
    "\n",
    "\n",
    "# The router() function determines the next tool to use based on the current state.\n",
    "def router(state: dict) -> str:\n",
    "    '''Determines the next tool to use based on the current state.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current state containing 'intermediate_steps'.\n",
    "\n",
    "    Returns:\n",
    "        str: The name of the tool to use next.\n",
    "    '''\n",
    "\n",
    "    if isinstance(state['intermediate_steps'], list):\n",
    "        return state['intermediate_steps'][-1].tool\n",
    "    else:\n",
    "        print('Router invalid format')\n",
    "        return 'final_answer'\n",
    "\n",
    "\n",
    "tool_str_to_func = {\n",
    "    'rag_search_filter': rag_search_filter,\n",
    "    'rag_search': rag_search,\n",
    "    'fetch_arxiv': fetch_arxiv,\n",
    "    'web_search': web_search,\n",
    "    'final_answer': final_answer\n",
    "}\n",
    "\n",
    "# The run_tool() function executes the appropriate tool based on the current state.\n",
    "def run_tool(state: dict) -> dict:\n",
    "    '''Executes the appropriate tool based on the current state.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current state containing the 'intermediate_steps'.\n",
    "\n",
    "    Returns:\n",
    "        dict: A new state with updated 'intermediate_steps' including the tool's result.\n",
    "    '''\n",
    "\n",
    "    tool_name = state['intermediate_steps'][-1].tool\n",
    "    tool_args = state['intermediate_steps'][-1].tool_input\n",
    "\n",
    "    print(f'{tool_name}.invoke(input={tool_args})')\n",
    "\n",
    "    out = tool_str_to_func[tool_name].invoke(input=tool_args)\n",
    "\n",
    "    action_out = AgentAction(\n",
    "        tool=tool_name,\n",
    "        tool_input=tool_args,\n",
    "        log=str(out)\n",
    "    )\n",
    "\n",
    "    return {'intermediate_steps': [action_out]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6791ed7d-a3a9-48b8-8d39-fee283ca1c7d",
   "metadata": {},
   "source": [
    "## 13 - Defining the Agent State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c74e9b7-de23-4ca9-91d8-44fc3e802ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Annotated, List\n",
    "from langchain_core.agents import AgentAction\n",
    "from langchain_core.messages import BaseMessage\n",
    "import operator\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    '''Represents the state of an agent.'''\n",
    "    \n",
    "    input: str\n",
    "    chat_history: List[BaseMessage]\n",
    "    intermediate_steps: Annotated[List[tuple[AgentAction, str]], operator.add]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e401aa-37ac-41e6-8354-8577d45ff181",
   "metadata": {},
   "source": [
    "## 14 - Defining the Graph for Decision-Making"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082644ad-8f9d-45f6-ad6b-d7c16d913bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "# Initialize the state graph with AgentState to manage the workflow.\n",
    "graph = StateGraph(AgentState)\n",
    "\n",
    "graph.add_node('oracle', run_oracle)\n",
    "graph.add_node('rag_search_filter', run_tool)\n",
    "graph.add_node('rag_search', run_tool)\n",
    "graph.add_node('fetch_arxiv', run_tool)\n",
    "graph.add_node('web_search', run_tool)\n",
    "graph.add_node('final_answer', run_tool)\n",
    "\n",
    "# Set the entry point to 'oracle'.\n",
    "graph.set_entry_point('oracle')\n",
    "\n",
    "# Add conditional edges to determine the next step using the router function.\n",
    "graph.add_conditional_edges(source='oracle', path=router)\n",
    "\n",
    "# Add edges from each tool back to 'oracle', except 'final_answer', which leads to 'END'.\n",
    "for tool_obj in tools:\n",
    "    if tool_obj.name != 'final_answer':\n",
    "        graph.add_edge(tool_obj.name, 'oracle')\n",
    "\n",
    "graph.add_edge('final_answer', END)\n",
    "\n",
    "# Compile the graph to make it executable.\n",
    "runnable = graph.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9425ac03-c31b-4b8f-94bc-7242f296b1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "# Display the graph as a PNG using Mermaid rendering.\n",
    "display(Image(runnable.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a900e779-d3f6-4176-92e1-a744b090ee67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the graph with input.\n",
    "output = runnable.invoke({\n",
    "    'input': 'Tell me something interesting about Dynamic Backtracking AI and LLMs',\n",
    "    'chat_history': [],\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5eb1bd-58cb-4d21-bb64-1d861e913a6e",
   "metadata": {},
   "source": [
    "## 15 - Generating Reports: Building a Formatted Final Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fa5027-2b1b-4dc3-a98e-2650778bf127",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_report(output: dict) -> str:\n",
    "    '''Builds a formatted report based on the oracle's output.\n",
    "\n",
    "    Args:\n",
    "        output (dict): A dictionary containing the various sections of the report (graph's output).\n",
    "\n",
    "    Returns:\n",
    "        str: A formatted string containing the full research report.\n",
    "    '''\n",
    "    research_steps = output['research_steps']\n",
    "    if isinstance(research_steps, list):\n",
    "        research_steps = '\\n'.join([f'- {r}' for r in research_steps])\n",
    "    \n",
    "    sources = output['sources']\n",
    "    if isinstance(sources, list):\n",
    "        sources = '\\n'.join([f'- {s}' for s in sources])\n",
    "    \n",
    "    return f\"\"\"\n",
    "        INTRODUCTION\n",
    "        ------------\n",
    "        {output['introduction']}\n",
    "        \n",
    "        RESEARCH STEPS\n",
    "        --------------\n",
    "        {research_steps}\n",
    "        \n",
    "        REPORT\n",
    "        ------\n",
    "        {output['main_body']}\n",
    "        \n",
    "        CONCLUSION\n",
    "        ----------\n",
    "        {output['conclusion']}\n",
    "        \n",
    "        SOURCES\n",
    "        -------\n",
    "        {sources}\n",
    "    \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0a7543-01ba-4511-bcc0-e6d30df52e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the graph with input.\n",
    "output = runnable.invoke({\n",
    "    'input': 'Tell me something interesting about Dynamic Backtracking AI and LLMs',\n",
    "    'chat_history': [],\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665e08cc-61ec-486d-8ae7-c98decdfafe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "output['intermediate_steps'][-1].tool_input "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129bb334-b71a-4aea-802d-e29630854152",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6bad122-b4dc-44ec-be8b-9db42ffdc666",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = runnable.invoke({\n",
    "    'input': 'tell me about FIFA World Cup 26',\n",
    "    'chat_history': []  \n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047ea374-c4a4-40c5-9feb-3221912906b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "report = build_report(\n",
    "    output=output['intermediate_steps'][-1].tool_input\n",
    ")\n",
    "\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130b6273-b4b6-4592-8d19-42134935f443",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = runnable.invoke({\n",
    "    'input': 'Create a summary about this AxXiv paper with the ID 2409.17990',\n",
    "    'chat_history': []\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e3c7a7-82c8-415b-9216-e15ac5544f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "report = build_report(\n",
    "    output=output['intermediate_steps'][-1].tool_input\n",
    ")\n",
    "\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c7c6e89f-38f9-4994-821f-3588ed683c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_oracle\n",
      "intermediate_steps: []\n",
      "rag_search.invoke(input={'query': 'future of LLM Agents'})\n",
      "run_oracle\n",
      "intermediate_steps: [AgentAction(tool='rag_search', tool_input={'query': 'future of LLM Agents'}, log='TBD'), AgentAction(tool='rag_search', tool_input={'query': 'future of LLM Agents'}, log='Title: On Planning while Learning\\nChunk: one go al/, if an e/\\x0ecient satisfactory multi/-agent plan for achievingthese go als exists/, then ther e exists such an e/\\x0ecient satisfactory multi/-agent plan that c anb e enc o de d in p olynomial sp ac e/, and b e veri/\\x0ce d in p olynomial time/.Pro of/: In this case eac h agen t kno ws the goal of the other agen t/, and hence it is clear thatit migh t learn only facts ab out the p ossible initial states and b eha viors/.Giv en that there is only a p olynomial n um b er of p ossible initial states and en\\nArXiv ID: 9409101v1\\n\\n---\\nTitle: A Market-Oriented Programming Environment and its Application to\\n  Distributed Multicommodity Flow Problems\\nChunk: can also b e addressed within w alras /. T o do so/, w e in tro duce y etanother sort of pro ducer agen t/. These new agen ts/, called arbitr ageurs /, act as sp ecializedmiddlemen/, monitoring isolated pieces of the net w ork for ine/\\x0eciencies/. An arbitrageurAi/;j/;k\\nArXiv ID: 9308102v1\\n\\n---\\nTitle: On Planning while Learning\\nChunk: k/, in p olynomialtime/, whether it determines a satisfactory m ulti/-agen t plan/.Lemma /6/./3 /: Given a quasi/-mo der ate multi/-agent Planning while L e arning system S /, wher ee ach agent has n p ossible go als /(wher e n is p olynomial ly b ounde d in the actual r epr esentationsize/)/, ther e exists a quasi/-mo der ate multi/-agent Planning while L e arning system S\\nArXiv ID: 9409101v1\\n\\n---\\nTitle: Software Agents: Completing Patterns and Constructing User Interfaces\\nChunk: S \\nCHLIMMER  \\n& H \\nERMENS \\n84 \\n• \\nUser adjustable \\n—Can the user tune the system parameters manually?\\nHere we describe related system s that exhibit propertie s in each of t hese agent dimensions .\\nOur note taking softwar e utilizes the  \\nanticipation \\n user interface technique pioneered by\\nEager (Cypher , 1991). Eager is a non-intrusive system that learns to perform iterative proce-\\ndures by watching the user . As such, it is a learning apprentice, a software agent , and an\\nArXiv ID: 9311102v1\\n\\n---\\nTitle: On Planning while Learning\\nChunk: /0/(wher equasi/-mo der ate r efers to the actual r epr esentation size of the original system S /)/, with aunique go al for e ach agent/, such that ther e exists an /(e/\\x0ecient/) satisfactory multi/-agent planin S\\n/0if and only if ther e exists an /(e/\\x0ecient/) satisfactory multi/-agent plan in S /.Pro of/: S\\n/0will b e built as follo ws/. The observ able states of agen t i in S\\n/0will b e the cartesianpro duct of the observ able states of agen t i in S with the set of states/:f star ti\\n/; obser v ei/1\\nArXiv ID: 9409101v1\\n')]\n",
      "web_search.invoke(input={'query': 'future of LLM Agents'})\n",
      "run_oracle\n",
      "intermediate_steps: [AgentAction(tool='rag_search', tool_input={'query': 'future of LLM Agents'}, log='TBD'), AgentAction(tool='rag_search', tool_input={'query': 'future of LLM Agents'}, log='Title: On Planning while Learning\\nChunk: one go al/, if an e/\\x0ecient satisfactory multi/-agent plan for achievingthese go als exists/, then ther e exists such an e/\\x0ecient satisfactory multi/-agent plan that c anb e enc o de d in p olynomial sp ac e/, and b e veri/\\x0ce d in p olynomial time/.Pro of/: In this case eac h agen t kno ws the goal of the other agen t/, and hence it is clear thatit migh t learn only facts ab out the p ossible initial states and b eha viors/.Giv en that there is only a p olynomial n um b er of p ossible initial states and en\\nArXiv ID: 9409101v1\\n\\n---\\nTitle: A Market-Oriented Programming Environment and its Application to\\n  Distributed Multicommodity Flow Problems\\nChunk: can also b e addressed within w alras /. T o do so/, w e in tro duce y etanother sort of pro ducer agen t/. These new agen ts/, called arbitr ageurs /, act as sp ecializedmiddlemen/, monitoring isolated pieces of the net w ork for ine/\\x0eciencies/. An arbitrageurAi/;j/;k\\nArXiv ID: 9308102v1\\n\\n---\\nTitle: On Planning while Learning\\nChunk: k/, in p olynomialtime/, whether it determines a satisfactory m ulti/-agen t plan/.Lemma /6/./3 /: Given a quasi/-mo der ate multi/-agent Planning while L e arning system S /, wher ee ach agent has n p ossible go als /(wher e n is p olynomial ly b ounde d in the actual r epr esentationsize/)/, ther e exists a quasi/-mo der ate multi/-agent Planning while L e arning system S\\nArXiv ID: 9409101v1\\n\\n---\\nTitle: Software Agents: Completing Patterns and Constructing User Interfaces\\nChunk: S \\nCHLIMMER  \\n& H \\nERMENS \\n84 \\n• \\nUser adjustable \\n—Can the user tune the system parameters manually?\\nHere we describe related system s that exhibit propertie s in each of t hese agent dimensions .\\nOur note taking softwar e utilizes the  \\nanticipation \\n user interface technique pioneered by\\nEager (Cypher , 1991). Eager is a non-intrusive system that learns to perform iterative proce-\\ndures by watching the user . As such, it is a learning apprentice, a software agent , and an\\nArXiv ID: 9311102v1\\n\\n---\\nTitle: On Planning while Learning\\nChunk: /0/(wher equasi/-mo der ate r efers to the actual r epr esentation size of the original system S /)/, with aunique go al for e ach agent/, such that ther e exists an /(e/\\x0ecient/) satisfactory multi/-agent planin S\\n/0if and only if ther e exists an /(e/\\x0ecient/) satisfactory multi/-agent plan in S /.Pro of/: S\\n/0will b e built as follo ws/. The observ able states of agen t i in S\\n/0will b e the cartesianpro duct of the observ able states of agen t i in S with the set of states/:f star ti\\n/; obser v ei/1\\nArXiv ID: 9409101v1\\n'), AgentAction(tool='web_search', tool_input={'query': 'future of LLM Agents'}, log='TBD'), AgentAction(tool='web_search', tool_input={'query': 'future of LLM Agents'}, log=\"The future of AI agents with Yohei Nakajima\\nThe future is going to be full of AI agents, but there are still a lot of open questions on how to get there & what that world will look like.\\nhttps://medium.com/around-the-prompt/the-future-of-ai-agents-with-yohei-nakajima-2602e32a4765\\n---\\nThe Future of LLM-Based Agents: Making the Boxes Bigger\\nThe Future of LLM-Based Agents: Making the Boxes Bigger | AI Agents are a promising approach for using Large Language Models (LLMs) to do real work.\\nhttps://www.arcus.co/blog/ai-agents-pt-2\\n---\\nLLM Agents: Their Past, Present, and Future\\nThe future of LLM agents is not just about creating smarter machines but about enhancing human capabilities and solving real-world problems ...\\nhttps://medium.com/@saurabhharak/llm-agents-their-past-present-and-future-22988c29a5f8\\n---\\nThe Future of Generative AI Agents\\nA series of in-depth conversations with leading AI researchers where we'll explore how state-of-the-art models are being applied in the real world.\\nhttps://foundationcapital.com/the-future-of-generative-agents/\")]\n",
      "rag_search_filter.invoke(input={'query': 'future of LLM Agents', 'arxiv_id': '9409101v1'})\n",
      "run_oracle\n",
      "intermediate_steps: [AgentAction(tool='rag_search', tool_input={'query': 'future of LLM Agents'}, log='TBD'), AgentAction(tool='rag_search', tool_input={'query': 'future of LLM Agents'}, log='Title: On Planning while Learning\\nChunk: one go al/, if an e/\\x0ecient satisfactory multi/-agent plan for achievingthese go als exists/, then ther e exists such an e/\\x0ecient satisfactory multi/-agent plan that c anb e enc o de d in p olynomial sp ac e/, and b e veri/\\x0ce d in p olynomial time/.Pro of/: In this case eac h agen t kno ws the goal of the other agen t/, and hence it is clear thatit migh t learn only facts ab out the p ossible initial states and b eha viors/.Giv en that there is only a p olynomial n um b er of p ossible initial states and en\\nArXiv ID: 9409101v1\\n\\n---\\nTitle: A Market-Oriented Programming Environment and its Application to\\n  Distributed Multicommodity Flow Problems\\nChunk: can also b e addressed within w alras /. T o do so/, w e in tro duce y etanother sort of pro ducer agen t/. These new agen ts/, called arbitr ageurs /, act as sp ecializedmiddlemen/, monitoring isolated pieces of the net w ork for ine/\\x0eciencies/. An arbitrageurAi/;j/;k\\nArXiv ID: 9308102v1\\n\\n---\\nTitle: On Planning while Learning\\nChunk: k/, in p olynomialtime/, whether it determines a satisfactory m ulti/-agen t plan/.Lemma /6/./3 /: Given a quasi/-mo der ate multi/-agent Planning while L e arning system S /, wher ee ach agent has n p ossible go als /(wher e n is p olynomial ly b ounde d in the actual r epr esentationsize/)/, ther e exists a quasi/-mo der ate multi/-agent Planning while L e arning system S\\nArXiv ID: 9409101v1\\n\\n---\\nTitle: Software Agents: Completing Patterns and Constructing User Interfaces\\nChunk: S \\nCHLIMMER  \\n& H \\nERMENS \\n84 \\n• \\nUser adjustable \\n—Can the user tune the system parameters manually?\\nHere we describe related system s that exhibit propertie s in each of t hese agent dimensions .\\nOur note taking softwar e utilizes the  \\nanticipation \\n user interface technique pioneered by\\nEager (Cypher , 1991). Eager is a non-intrusive system that learns to perform iterative proce-\\ndures by watching the user . As such, it is a learning apprentice, a software agent , and an\\nArXiv ID: 9311102v1\\n\\n---\\nTitle: On Planning while Learning\\nChunk: /0/(wher equasi/-mo der ate r efers to the actual r epr esentation size of the original system S /)/, with aunique go al for e ach agent/, such that ther e exists an /(e/\\x0ecient/) satisfactory multi/-agent planin S\\n/0if and only if ther e exists an /(e/\\x0ecient/) satisfactory multi/-agent plan in S /.Pro of/: S\\n/0will b e built as follo ws/. The observ able states of agen t i in S\\n/0will b e the cartesianpro duct of the observ able states of agen t i in S with the set of states/:f star ti\\n/; obser v ei/1\\nArXiv ID: 9409101v1\\n'), AgentAction(tool='web_search', tool_input={'query': 'future of LLM Agents'}, log='TBD'), AgentAction(tool='web_search', tool_input={'query': 'future of LLM Agents'}, log=\"The future of AI agents with Yohei Nakajima\\nThe future is going to be full of AI agents, but there are still a lot of open questions on how to get there & what that world will look like.\\nhttps://medium.com/around-the-prompt/the-future-of-ai-agents-with-yohei-nakajima-2602e32a4765\\n---\\nThe Future of LLM-Based Agents: Making the Boxes Bigger\\nThe Future of LLM-Based Agents: Making the Boxes Bigger | AI Agents are a promising approach for using Large Language Models (LLMs) to do real work.\\nhttps://www.arcus.co/blog/ai-agents-pt-2\\n---\\nLLM Agents: Their Past, Present, and Future\\nThe future of LLM agents is not just about creating smarter machines but about enhancing human capabilities and solving real-world problems ...\\nhttps://medium.com/@saurabhharak/llm-agents-their-past-present-and-future-22988c29a5f8\\n---\\nThe Future of Generative AI Agents\\nA series of in-depth conversations with leading AI researchers where we'll explore how state-of-the-art models are being applied in the real world.\\nhttps://foundationcapital.com/the-future-of-generative-agents/\"), AgentAction(tool='rag_search_filter', tool_input={'query': 'future of LLM Agents', 'arxiv_id': '9409101v1'}, log='TBD'), AgentAction(tool='rag_search_filter', tool_input={'query': 'future of LLM Agents', 'arxiv_id': '9409101v1'}, log=\"Title: On Planning while Learning\\nChunk: one go al/, if an e/\\x0ecient satisfactory multi/-agent plan for achievingthese go als exists/, then ther e exists such an e/\\x0ecient satisfactory multi/-agent plan that c anb e enc o de d in p olynomial sp ac e/, and b e veri/\\x0ce d in p olynomial time/.Pro of/: In this case eac h agen t kno ws the goal of the other agen t/, and hence it is clear thatit migh t learn only facts ab out the p ossible initial states and b eha viors/.Giv en that there is only a p olynomial n um b er of p ossible initial states and en\\nArXiv ID: 9409101v1\\n\\n---\\nTitle: On Planning while Learning\\nChunk: k/, in p olynomialtime/, whether it determines a satisfactory m ulti/-agen t plan/.Lemma /6/./3 /: Given a quasi/-mo der ate multi/-agent Planning while L e arning system S /, wher ee ach agent has n p ossible go als /(wher e n is p olynomial ly b ounde d in the actual r epr esentationsize/)/, ther e exists a quasi/-mo der ate multi/-agent Planning while L e arning system S\\nArXiv ID: 9409101v1\\n\\n---\\nTitle: On Planning while Learning\\nChunk: /0/(wher equasi/-mo der ate r efers to the actual r epr esentation size of the original system S /)/, with aunique go al for e ach agent/, such that ther e exists an /(e/\\x0ecient/) satisfactory multi/-agent planin S\\n/0if and only if ther e exists an /(e/\\x0ecient/) satisfactory multi/-agent plan in S /.Pro of/: S\\n/0will b e built as follo ws/. The observ able states of agen t i in S\\n/0will b e the cartesianpro duct of the observ able states of agen t i in S with the set of states/:f star ti\\n/; obser v ei/1\\nArXiv ID: 9409101v1\\n\\n---\\nTitle: On Planning while Learning\\nChunk: /4An in teresting feature of the m ulti/-agen t case is that an agen t migh t not b e familiarwith the goal and the initial state of the other agen t/. Hence/, Planning while Learning refersno w to the case in whic h an agen t tries to ac hiev e its goal while learning ab out the b eha viorof the en vironmen t/, and ab out the goals and initial states of other agen ts/.De/\\x0cnition /6/./2 /: A multi/-agent Planning while L e arning system is a tupleSm\\n/= /( Q/1\\n/; Q/2\\n/; A /; q\\n/1/0\\n/; q\\n/2/0\\n/; B /; b/0\\nArXiv ID: 9409101v1\\n\\n---\\nTitle: On Planning while Learning\\nChunk: On Planning while Learningof other agen ts/' mo v emen ts/. It is easy to see that similar scenarios o ccur in the trauma/-careexample and in man y other natural systems/.W e no w sho w that our o/\\x0b/-line tractabilit y result can b e extended to the m ulti/-agen tcase as w ell/. W e will use the follo wing t w o lemmas/.Lemma /6/./2 /: Given a quasi/-mo der ate multi/-agent Planning while L e arning system/, wher ee ach agent has only one go al/, if an e/\\x0ecient satisfactory multi/-agent plan for\\nArXiv ID: 9409101v1\\n\\n---\\nTitle: On Planning while Learning\\nChunk: /) and initial state of the other agen t/, and regardlessof the initial b eha vior of the en vironmen t/. An e/\\x0ecient satisfactory multi/-agent plan is asatisfactory m ulti/-agen t plan that consists of plans whic h are decision trees of p olynomialdepth/.The ab o v e de/\\x0cnition captures in tuitiv e situations of Planning while Learning in m ulti/-agen t domains/. Assume for example that there are t w o forces that ha v e to mo v e in thehostile en vironmen t of Section /2/. They start mo ving on /5AM/,\\nArXiv ID: 9409101v1\\n\")]\n",
      "final_answer.invoke(input={'introduction': 'The future of Large Language Model (LLM) Agents is a topic of significant interest and speculation in the field of artificial intelligence. These agents, powered by advanced language models, are expected to revolutionize various industries by enhancing human capabilities and solving complex problems.', 'research_steps': \"1. Conducted a specialized search on AI using the query 'future of LLM Agents'.\\n2. Performed a web search to gather general knowledge on the topic.\\n3. Filtered ArXiv papers to find relevant academic insights on multi-agent systems and planning while learning.\", 'main_body': 'LLM Agents are poised to become integral components of future AI systems, offering capabilities that extend beyond traditional software agents. These agents are designed to understand and generate human-like text, making them suitable for a wide range of applications, from customer service to complex decision-making processes. The development of LLM Agents is driven by the need to create systems that can learn and adapt in real-time, providing more personalized and efficient interactions.\\n\\nOne of the key areas of focus for the future of LLM Agents is their ability to work collaboratively in multi-agent environments. Research indicates that these agents can be programmed to achieve goals efficiently by learning from their environment and other agents. This capability is crucial for applications in fields such as logistics, healthcare, and finance, where multiple agents must coordinate to achieve optimal outcomes.\\n\\nMoreover, the integration of LLM Agents into existing systems is expected to enhance human capabilities by automating routine tasks and providing insights that were previously inaccessible. This transformation will likely lead to increased productivity and innovation across various sectors. However, the path to realizing the full potential of LLM Agents is fraught with challenges, including ethical considerations, data privacy, and the need for robust regulatory frameworks.', 'conclusion': 'The future of LLM Agents is promising, with the potential to transform industries and improve human-machine interactions. As these agents become more sophisticated, they will play a crucial role in addressing complex challenges and enhancing human capabilities. Continued research and development, along with careful consideration of ethical and regulatory issues, will be essential to harnessing the full potential of LLM Agents.', 'sources': \"1. ArXiv paper on multi-agent planning and learning (ArXiv ID: 9409101v1)\\n2. Medium article on the future of AI agents\\n3. Arcus blog on LLM-based agents\\n4. Foundation Capital's exploration of generative AI agents\"})\n",
      "\n",
      "        INTRODUCTION\n",
      "        ------------\n",
      "        The future of Large Language Model (LLM) Agents is a topic of significant interest and speculation in the field of artificial intelligence. These agents, powered by advanced language models, are expected to revolutionize various industries by enhancing human capabilities and solving complex problems.\n",
      "        \n",
      "        RESEARCH STEPS\n",
      "        --------------\n",
      "        1. Conducted a specialized search on AI using the query 'future of LLM Agents'.\n",
      "2. Performed a web search to gather general knowledge on the topic.\n",
      "3. Filtered ArXiv papers to find relevant academic insights on multi-agent systems and planning while learning.\n",
      "        \n",
      "        REPORT\n",
      "        ------\n",
      "        LLM Agents are poised to become integral components of future AI systems, offering capabilities that extend beyond traditional software agents. These agents are designed to understand and generate human-like text, making them suitable for a wide range of applications, from customer service to complex decision-making processes. The development of LLM Agents is driven by the need to create systems that can learn and adapt in real-time, providing more personalized and efficient interactions.\n",
      "\n",
      "One of the key areas of focus for the future of LLM Agents is their ability to work collaboratively in multi-agent environments. Research indicates that these agents can be programmed to achieve goals efficiently by learning from their environment and other agents. This capability is crucial for applications in fields such as logistics, healthcare, and finance, where multiple agents must coordinate to achieve optimal outcomes.\n",
      "\n",
      "Moreover, the integration of LLM Agents into existing systems is expected to enhance human capabilities by automating routine tasks and providing insights that were previously inaccessible. This transformation will likely lead to increased productivity and innovation across various sectors. However, the path to realizing the full potential of LLM Agents is fraught with challenges, including ethical considerations, data privacy, and the need for robust regulatory frameworks.\n",
      "        \n",
      "        CONCLUSION\n",
      "        ----------\n",
      "        The future of LLM Agents is promising, with the potential to transform industries and improve human-machine interactions. As these agents become more sophisticated, they will play a crucial role in addressing complex challenges and enhancing human capabilities. Continued research and development, along with careful consideration of ethical and regulatory issues, will be essential to harnessing the full potential of LLM Agents.\n",
      "        \n",
      "        SOURCES\n",
      "        -------\n",
      "        1. ArXiv paper on multi-agent planning and learning (ArXiv ID: 9409101v1)\n",
      "2. Medium article on the future of AI agents\n",
      "3. Arcus blog on LLM-based agents\n",
      "4. Foundation Capital's exploration of generative AI agents\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "output = runnable.invoke({\n",
    "    'input': 'Create a summary about the future of LLM Agents.',\n",
    "    'chat_history': []\n",
    "})\n",
    "\n",
    "report = build_report(\n",
    "    output=output['intermediate_steps'][-1].tool_input\n",
    ")\n",
    "\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1180d5b1-e62f-42b2-9040-24c49259b2f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589e6c67-e37d-4f4d-abe0-1dddebf6842f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
